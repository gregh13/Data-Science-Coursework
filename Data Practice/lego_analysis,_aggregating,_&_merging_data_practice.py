# -*- coding: utf-8 -*-
"""Lego Analysis, Aggregating, & Merging Data Practice

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6usRtsw2silSIqMrE-OecQI-cX5zS49

# Introduction

Today we'll dive deep into a dataset all about LEGO. From the dataset we can ask whole bunch of interesting questions about the history of the LEGO company, their product offering, and which LEGO set ultimately rules them all:

<ul type="square">
<li>What is the most enormous LEGO set ever created and how many parts did it have?</li>

<li>How did the LEGO company start out? In which year were the first LEGO sets released and how many sets did the company sell when it first launched?</li>

<li>Which LEGO theme has the most sets? Is it one of LEGO's own themes like Ninjago or a theme they licensed liked Harry Potter or Marvel Superheroes?</li>

<li>When did the LEGO company really expand its product offering? Can we spot a change in the company strategy based on how many themes and sets did it released year-on-year?</li>

<li>Did LEGO sets grow in size and complexity over time? Do older LEGO 
sets tend to have more or fewer parts than newer sets?</li>
</ul>

**Data Source**

[Rebrickable](https://rebrickable.com/downloads/) has compiled data on all the LEGO pieces in existence. I recommend you use download the .csv files provided in this lesson.

# Import Statements
"""

import pandas as pd
import matplotlib.pyplot as plt

"""# Data Exploration

**Challenge**: How many different colours does the LEGO company produce? Read the colors.csv file in the data folder and find the total number of unique colours. Try using the [.nunique() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html?highlight=nunique#pandas.DataFrame.nunique) to accomplish this.
"""

colors_df = pd.read_csv('colors.csv')
colors_df

colors_df.nunique()

"""**Challenge**: Find the number of transparent colours where <code>is_trans == 't'</code> versus the number of opaque colours where <code>is_trans == 'f'</code>. See if you can accomplish this in two different ways."""

colors_df.groupby('is_trans').count()

transparent_df = colors_df.pivot(index='id', columns='is_trans', values='rgb')
transparent_df.f.count()

# Or, another easier way than pivoting, similar to the first option = value_counts()
colors_df.is_trans.value_counts()

"""###Understanding LEGO Themes vs. LEGO Sets

Walk into a LEGO store and you will see their products organised by theme. Their themes include Star Wars, Batman, Harry Potter and many more.

<img src="https://i.imgur.com/aKcwkSx.png">

A lego **set** is a particular box of LEGO or product. Therefore, a single theme typically has many different sets.

<img src="https://i.imgur.com/whB1olq.png">

The <code>sets.csv</code> data contains a list of sets over the years and the number of parts that each of these sets contained.

**Challenge**: Read the sets.csv data and take a look at the first and last couple of rows.
"""

sets_df = pd.read_csv('sets.csv')

sets_df

"""**Challenge**: In which year were the first LEGO sets released and what were these sets called?"""

sets_df.sort_values('year').head(n=10)

"""**Challenge**: How many different sets did LEGO sell in their first year? How many types of LEGO products were on offer in the year the company started?"""

# Call the column in the df, set it equal to the value you want to isolate
# then call THAT inside the df to get all the rows that match that data piece
first_year = sets_df[sets_df['year'] == 1949]
first_year

first_year['num_parts'].sum()

"""**Challenge**: Find the top 5 LEGO sets with the most number of parts. """

sets_df.sort_values('num_parts', ascending=False).head()

"""**Challenge**: Use <code>.groupby()</code> and <code>.count()</code> to show the number of LEGO sets released year-on-year. How do the number of sets released in 1955 compare to the number of sets released in 2019? """

# .count() works well here since we are trying to get the NUMBER of sets made. For other aggregate data, we need the .agg() used later on below
sets_by_year = sets_df.groupby('year').count()
sets_by_year['set_num']

plt.plot(sets_by_year.index, sets_by_year['set_num'])

"""**Challenge**: Show the number of LEGO releases on a line chart using Matplotlib. <br>
<br>
Note that the .csv file is from late 2020, so to plot the full calendar years, you will have to exclude some data from your chart. Can you use the slicing techniques covered in Day 21 to avoid plotting the last two years? The same syntax will work on Pandas DataFrames. 
"""

# Table had 71 rows of data. Slice on both x and y if doing it at a later stage (just once if crafting variable set)
# Note can use 71-2= 69 or just -2
sets_by_year['set_num'][:69]
plt.plot(sets_by_year.index[:69], sets_by_year['set_num'][:-2])

"""### Aggregate Data with the Python .agg() Function

Let's work out the number of different themes shipped by year. This means we have to count the number of unique theme_ids per calendar year.
"""

# So we groupby, then agg. agg() takes a dictioniary, using the column name and then the Series (since is a column) nunique
themes_by_year = sets_df.groupby('year').agg({'theme_id':pd.Series.nunique})
themes_by_year

# Since we have to use the column names in the original df to aggregate, we can use this to change the name for our new column
# Note it does not affect the original df, just the newly created aggregated column we made
themes_by_year.rename(columns = {'theme_id': 'nr_themes'}, inplace=True)
themes_by_year

"""**Challenge**: Plot the number of themes released by year on a line chart. Only include the full calendar years (i.e., exclude 2020 and 2021). """

plt.plot(themes_by_year[:-2])

"""### Line Charts with Two Seperate Axes"""

# To graph two lines with very different scales, we can use separate axis
ax1 = plt.gca() # get current axes
ax2 = ax1.twinx() 

# Instead of using plt, we call the axis object directly
ax1.plot(sets_by_year[:-2], label=sets_by_year["set_num"].name, color="g")
ax2.plot(themes_by_year[:-2], label=themes_by_year["nr_themes"].name, color="b")

ax1.set_xlabel('\nYear', fontsize=14)
ax1.set_ylabel('Number of Sets', color='green')
ax2.set_ylabel('Number of Themes', color='blue')

"""**Challenge**: Use the <code>.groupby()</code> and <code>.agg()</code> function together to figure out the average number of parts per set. How many parts did the average LEGO set released in 1954 compared to say, 2017?"""

parts_per_year = sets_df.groupby('year').agg({'num_parts': pd.Series.mean})[:-2]
parts_per_year

"""### Scatter Plots in Matplotlib

**Challenge**: Has the size and complexity of LEGO sets increased over time based on the number of parts? Plot the average number of parts over time using a Matplotlib scatter plot. See if you can use the [scatter plot documentation](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.scatter.html) before I show you the solution. Do you spot a trend in the chart?
"""

# Note data only goes til 2019 since parts_per_year was sliced above to exclude 2020 adnd 2021
plt.xlabel('Year', fontsize=14)
plt.ylabel('Average\nNumber of Parts', fontsize=14)
plt.scatter(parts_per_year.index, parts_per_year['num_parts'])

"""### Number of Sets per LEGO Theme

LEGO has licensed many hit franchises from Harry Potter to Marvel Super Heros to many others. But which theme has the largest number of individual sets?
"""

# note that value_counts() automatically displays sorted descending order
sets_df.theme_id.value_counts()

"""<img src="https://i.imgur.com/Sg4lcjx.png">

### Database Schemas, Foreign Keys and Merging DataFrames

The themes.csv file has the actual theme names. The sets .csv has <code>theme_ids</code> which link to the <code>id</code> column in the themes.csv.

**Challenge**: Explore the themes.csv. How is it structured? Search for the name 'Star Wars'. How many <code>id</code>s correspond to this name in the themes.csv? Now use these <code>id</code>s and find the corresponding sets in the sets.csv (Hint: you'll need to look for matches in the <code>theme_id</code> column)
"""

themes_df = pd.read_csv('themes.csv')

themes_df

star_wars = themes_df[themes_df.name == 'Star Wars']
display(star_wars)
star_wars_ids = star_wars.id.values
display(star_wars_ids)

# Searching within a dataframe for data that meets our search criteria
sets_df[sets_df.theme_id == 158]

# Very manual way to do it, lots of extra work done (see below for faster method with .agg())
total_sets = 0
# Loop through each Star Wars id and calculate total number of Star Wars sets
for id_val in star_wars_ids:
  sw_set = sets_df[sets_df.theme_id == id_val]
  display(sw_set)
  display(sw_set.shape)
  total_sets += sw_set.shape[0]
print(f"\nTotal Star Wars Sets: ", total_sets)

sets_by_theme = sets_df.groupby('theme_id').agg({'set_num':pd.Series.count})
sets_by_theme.sort_values('set_num', ascending=False, inplace=True)
sets_by_theme

# Better than before, just loop through index list and add each value to total
total_count = 0
for id in star_wars_ids:
  val = sets_by_theme.loc[id].values
  total_count += val[0]
print(f"\nTotal Star Wars Sets: ", total_count)

# Even better! Pass through index list into .loc and returns df with just those rows. Use sum() to quickly total
starwars_df = sets_by_theme.loc[star_wars_ids]
total = starwars_df.sum().values[0]
print(f"\nTotal Star Wars Sets: ", total)

"""### Merging (i.e., Combining) DataFrames based on a Key

"""

# Even though it has the theme_id as the index, this will still work for merging DataFrames since it's the 'id' column we merge on
# We use a dictioinary to create the new DataFrame {'column_name':column_values}
# Note: using the name 'id' since it matches the other table we want to merge with.
set_theme_count_df = pd.DataFrame({'id':sets_by_theme.index, 
                                   'set_count':sets_by_theme.set_num})

set_theme_count_df

# on= is the column name we need to use to merge the two together
merged1_df = pd.merge(set_theme_count_df, themes_df, on='id')
merged1_df

# By using value_counts, we create a set that is a bit cleaner since the index is normal - HER WAY
# EXTRA WAY
theme_counts = sets_df.theme_id.value_counts()
theme_counts

# We use a dictioinary to create the new DataFrame {'column_name':column_values}
# Note: using the name 'id' since it matches the other table we want to merge with.
set_theme_count_df = pd.DataFrame({'id':theme_counts.index, 
                                   'set_count':theme_counts.values})
set_theme_count_df

# on= is the column name we need to use to merge the two together
top_ten_merged_df = pd.merge(set_theme_count_df, themes_df, on='id')[:10]
top_ten_merged_df

plt.bar(top_ten_merged_df.name, top_ten_merged_df.set_count)

# Let's configure our bar graph so it's more readable
# Note the rotation for the xticks since they overlap

plt.figure(figsize=(18,10))
plt.xlabel('\nTheme', fontsize=18)
plt.ylabel('Number of Sets\n', fontsize=18)
plt.xticks(fontsize=14, rotation=45)
plt.yticks(fontsize=14)

plt.bar(top_ten_merged_df.name, top_ten_merged_df.set_count)